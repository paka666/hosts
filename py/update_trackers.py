#!/usr/bin/env python3
"""
Trackeråˆ—è¡¨è§„èŒƒåŒ–è„šæœ¬ - å¥å£®ç‰ˆæœ¬
å¤„ç†å¤šURLæºå’Œæœ¬åœ°trackers-back.txtï¼Œè§„èŒƒåŒ–æ ¼å¼å¹¶è‡ªåŠ¨å¤‡ä»½
"""

import requests
from urllib.parse import urlparse, urlunparse
import re
import os
import time
import glob
import shutil
from ipaddress import IPv6Address, IPv4Address, AddressValueError

# URLæºåˆ—è¡¨
TRACKER_URLS = [
    "http://github.itzmx.com/1265578519/OpenTracker/master/tracker.txt",
    "https://cf.trackerslist.com/all.txt",
    "https://cf.trackerslist.com/best.txt",
    "https://cf.trackerslist.com/http.txt",
    "https://cf.trackerslist.com/nohttp.txt",
    "https://github.itzmx.com/1265578519/OpenTracker/master/tracker.txt",
    "https://newtrackon.com/api/10",
    "https://newtrackon.com/api/all",
    "https://newtrackon.com/api/http",
    "https://newtrackon.com/api/live",
    "https://newtrackon.com/api/stable",
    "https://newtrackon.com/api/udp",
    "https://raw.githubusercontent.com/DeSireFire/animeTrackerList/master/AT_all.txt",
    "https://raw.githubusercontent.com/DeSireFire/animeTrackerList/master/AT_all_http.txt",
    "https://raw.githubusercontent.com/DeSireFire/animeTrackerList/master/AT_all_https.txt",
    "https://raw.githubusercontent.com/DeSireFire/animeTrackerList/master/AT_all_ip.txt",
    "https://raw.githubusercontent.com/DeSireFire/animeTrackerList/master/AT_all_udp.txt",
    "https://raw.githubusercontent.com/DeSireFire/animeTrackerList/master/AT_all_ws.txt",
    "https://raw.githubusercontent.com/DeSireFire/animeTrackerList/master/AT_bad.txt",
    "https://raw.githubusercontent.com/DeSireFire/animeTrackerList/master/AT_best.txt",
    "https://raw.githubusercontent.com/DeSireFire/animeTrackerList/master/AT_best_ip.txt",
    "https://raw.githubusercontent.com/XIU2/TrackersListCollection/master/all.txt",
    "https://raw.githubusercontent.com/XIU2/TrackersListCollection/master/best.txt",
    "https://raw.githubusercontent.com/ngosang/trackerslist/master/trackers_all.txt",
    "https://raw.githubusercontent.com/ngosang/trackerslist/master/trackers_all_http.txt",
    "https://raw.githubusercontent.com/ngosang/trackerslist/master/trackers_all_https.txt",
    "https://raw.githubusercontent.com/ngosang/trackerslist/master/trackers_all_i2p.txt",
    "https://raw.githubusercontent.com/ngosang/trackerslist/master/trackers_all_ip.txt",
    "https://raw.githubusercontent.com/ngosang/trackerslist/master/trackers_all_udp.txt",
    "https://raw.githubusercontent.com/ngosang/trackerslist/master/trackers_all_ws.txt",
    "https://raw.githubusercontent.com/ngosang/trackerslist/master/trackers_best.txt",
    "https://raw.githubusercontent.com/ngosang/trackerslist/master/trackers_best_ip.txt",
    "https://torrends.to/torrent-tracker-list/?download=latest",
    "https://trackerslist.com/all.txt",
    "https://trackerslist.com/best.txt",
    "https://trackerslist.com/http.txt"
]

# é…ç½®å¸¸é‡
LOCAL_TRACKER_FILE = "trackers/trackers-back.txt"
BACKUP_KEEP_COUNT = 3
REQUEST_TIMEOUT = 15

# æ”¯æŒçš„åè®®
SUPPORTED_SCHEMES = {"http", "https", "udp", "ws", "wss"}

# é»˜è®¤ç«¯å£æ˜ å°„
DEFAULT_PORTS = {
    "http": 80,
    "https": 443, 
    "ws": 80,
    "wss": 443
}

def fetch_all_sources():
    """ä»æ‰€æœ‰URLæºå’Œæœ¬åœ°æ–‡ä»¶è·å–trackeræ•°æ®"""
    print("ğŸ“¡ è·å–trackeræ•°æ®...")
    contents = []
    
    # ä»URLè·å–
    for url in TRACKER_URLS:
        try:
            response = requests.get(url, timeout=REQUEST_TIMEOUT)
            response.raise_for_status()
            contents.append(response.text)
            print(f"âœ… æˆåŠŸè·å–: {url}")
        except Exception as e:
            print(f"âŒ è·å–å¤±è´¥ {url}: {e}")
    
    # ä»æœ¬åœ°æ–‡ä»¶è·å–
    if os.path.exists(LOCAL_TRACKER_FILE):
        try:
            with open(LOCAL_TRACKER_FILE, "r", encoding="utf-8") as f:
                contents.append(f.read())
            print(f"âœ… æˆåŠŸè¯»å–æœ¬åœ°æ–‡ä»¶: {LOCAL_TRACKER_FILE}")
        except Exception as e:
            print(f"âŒ è¯»å–æœ¬åœ°æ–‡ä»¶å¤±è´¥: {e}")
    
    return "\n".join(contents)

def clean_and_split_text(text):
    """æ¸…ç†æ–‡æœ¬ï¼šå»é™¤æ³¨é‡Šã€ç©ºç™½å­—ç¬¦ã€åˆ†å‰²æˆç‹¬ç«‹tracker"""
    print("ğŸ§¹ æ¸…ç†å’Œåˆ†å‰²æ•°æ®...")
    lines = text.splitlines()
    cleaned = []
    
    for line in lines:
        # å»é™¤æ³¨é‡Š (# ! ;)
        line = re.split(r"[#!;]", line)[0].strip()
        if not line:
            continue
            
        # åˆ†å‰²é€—å·ã€åˆ†å·ã€ç©ºç™½å­—ç¬¦
        parts = [part.strip() for part in re.split(r"[ ,;]+", line) if part.strip()]
        cleaned.extend(parts)
    
    print(f"ğŸ“Š åˆå§‹æ¸…ç†å: {len(cleaned)} ä¸ªtracker")
    return cleaned

def fix_protocol_format(trackers):
    """ä¿®å¤åè®®æ ¼å¼é”™è¯¯"""
    print("ğŸ”§ ä¿®å¤åè®®æ ¼å¼...")
    fixed = []
    
    protocol_fixes = {
        "http:/": "http://",
        "https:/": "https://", 
        "udp:/": "udp://",
        "ws:/": "ws://",
        "wss:/": "wss://"
    }
    
    for tracker in trackers:
        # ä¿®å¤ç¼ºå¤±åŒæ–œæ çš„åè®®
        for wrong, correct in protocol_fixes.items():
            if tracker.startswith(wrong):
                tracker = correct + tracker[len(wrong):]
                break
        fixed.append(tracker)
    
    return fixed

def split_concatenated_trackers(trackers):
    """åˆ†ç¦»ç²˜è¿çš„tracker"""
    print("ğŸ”€ åˆ†ç¦»ç²˜è¿tracker...")
    split_trackers = []
    
    # åè®®æ¨¡å¼
    protocol_pattern = r"(https?://|udp://|ws://|wss://)"
    
    for tracker in trackers:
        # æŸ¥æ‰¾æ‰€æœ‰åè®®å¼€å§‹ä½ç½®
        matches = list(re.finditer(protocol_pattern, tracker, re.IGNORECASE))
        
        if len(matches) <= 1:
            split_trackers.append(tracker)
            continue
            
        # åˆ†ç¦»å¤šä¸ªtracker
        for i, match in enumerate(matches):
            start_pos = match.start()
            if i + 1 < len(matches):
                end_pos = matches[i + 1].start()
            else:
                end_pos = len(tracker)
            
            single_tracker = tracker[start_pos:end_pos].strip()
            if single_tracker and not single_tracker.endswith('://'):
                split_trackers.append(single_tracker)
    
    print(f"ğŸ“Š åˆ†ç¦»å: {len(split_trackers)} ä¸ªtracker")
    return split_trackers

def handle_protocol_prefix_concatenation(trackers):
    """å¤„ç†åè®®å‰ç¼€ç²˜è¿ (å¦‚ udp://http://wss://...)"""
    print("ğŸ”„ å¤„ç†åè®®å‰ç¼€ç²˜è¿...")
    processed = []
    
    for tracker in trackers:
        # åŒ¹é…å¤šä¸ªåè®®å‰ç¼€
        match = re.match(r'^((?:https?|udp|ws|wss)://?)+(.+)$', tracker, re.IGNORECASE)
        if match:
            protocols_part = match.group(1)
            suffix = match.group(2)
            
            # æå–æ‰€æœ‰åè®®
            found_protocols = set(re.findall(r'(https?|udp|ws|wss)', protocols_part, re.IGNORECASE))
            
            # ä¸ºæ¯ä¸ªåè®®åˆ›å»ºtracker
            for protocol in found_protocols:
                processed.append(f"{protocol.lower()}://{suffix}")
        else:
            processed.append(tracker)
    
    return processed

def is_valid_hostname(hostname):
    """éªŒè¯ä¸»æœºåæ˜¯å¦æœ‰æ•ˆ"""
    if not hostname:
        return False
        
    # localhost æ˜¯æœ‰æ•ˆçš„
    if hostname.lower() == 'localhost':
        return True
    
    # æ£€æŸ¥IPv4
    try:
        IPv4Address(hostname)
        return True
    except AddressValueError:
        pass
    
    # æ£€æŸ¥IPv6 (å¯èƒ½å¸¦æ–¹æ‹¬å·)
    host_to_check = hostname
    if host_to_check.startswith('[') and host_to_check.endswith(']'):
        host_to_check = host_to_check[1:-1]
    
    try:
        IPv6Address(host_to_check)
        return True
    except AddressValueError:
        pass
    
    # æ£€æŸ¥åŸŸåï¼šåªè¦åŒ…å«ç‚¹å°±è®¤ä¸ºæ˜¯æœ‰æ•ˆåŸŸå
    # è¿™è¿‡æ»¤æ‰ç±»ä¼¼ 'ipv4announce' çš„æ— ç‚¹ä¸»æœºå
    if '.' in hostname:
        return True
        
    return False

def normalize_tracker_url(tracker):
    """è§„èŒƒåŒ–å•ä¸ªtracker URL"""
    try:
        # åŸºç¡€æ¸…ç†
        tracker = tracker.strip()
        if not tracker:
            return None
        
        # è§£æURL
        parsed = urlparse(tracker)
        
        # éªŒè¯åè®®
        if not parsed.scheme or parsed.scheme.lower() not in SUPPORTED_SCHEMES:
            return None
            
        # éªŒè¯netloc
        if not parsed.netloc:
            return None
        
        # æå–ä¸»æœºåå’Œç«¯å£
        hostname = parsed.hostname
        port = parsed.port
        
        # éªŒè¯ä¸»æœºå
        if not is_valid_hostname(hostname):
            return None
        
        # å¤„ç†æ–¹æ‹¬å·ï¼ˆIPv6å’Œé”™è¯¯ä½¿ç”¨ï¼‰
        netloc = parsed.netloc
        if '[' in netloc and ']' in netloc:
            # æå–æ–¹æ‹¬å·å†…å†…å®¹
            bracket_content = re.search(r'\[([^]]+)\]', netloc)
            if bracket_content:
                inside = bracket_content.group(1)
                try:
                    # å¦‚æœæ˜¯åˆæ³•IPv6ï¼Œä¿ç•™æ–¹æ‹¬å·
                    IPv6Address(inside)
                    # ä¿æŒåŸæ ·
                except AddressValueError:
                    # ä¸æ˜¯IPv6ï¼Œç§»é™¤æ–¹æ‹¬å·
                    netloc = netloc.replace(f'[{inside}]', inside)
                    # é‡æ–°è§£æ
                    parsed = urlparse(parsed._replace(netloc=netloc).geturl())
        
        # ä¿®å¤ç²˜è¿ç«¯å£ (å¦‚ .com80 -> .com:80)
        if not port:
            port_match = re.match(r'^(.+?[a-zA-Z.-])(\d+)$', parsed.netloc)
            if port_match:
                base_host, port_str = port_match.groups()
                if port_str.isdigit() and 1 <= int(port_str) <= 65535:
                    if is_valid_hostname(base_host.rstrip('.')):
                        new_netloc = f"{base_host.rstrip('.')}:{port_str}"
                        parsed = parsed._replace(netloc=new_netloc)
        
        # å¤„ç†è·¯å¾„
        path = parsed.path
        
        # ä¿®å¤åŒæ–œæ 
        path = re.sub(r'//+', '/', path)
        
        # ä¿®å¤announceè·¯å¾„é—®é¢˜
        path = path.replace('//announce', '/announce')
        path = re.sub(r'/announce(\+\d*|"|\+)?$', '/announce', path)
        
        # æ£€æŸ¥æ˜¯å¦éœ€è¦æ·»åŠ /announce
        valid_suffixes = [
            r'\.i2p(:\d+)?/a',
            r'/announce(\.php)?(\?(passkey|authkey)=[^/?&]+)?',
            r'/announce(\.php)?/[^/?]+$',
            r'/a$'  # I2P tracker
        ]
        
        has_valid_suffix = any(re.search(pattern, path, re.IGNORECASE) for pattern in valid_suffixes)
        
        if not has_valid_suffix:
            if not path or path == '/':
                path = '/announce'
            elif not path.endswith('/announce'):
                # é¿å…é‡å¤æ·»åŠ 
                if not re.search(r'/announce([/?]|$)', path):
                    path = path.rstrip('/') + '/announce'
        
        # é‡å»ºURL
        normalized_url = urlunparse((
            parsed.scheme,
            parsed.netloc,
            path,
            parsed.params,
            parsed.query,
            parsed.fragment
        ))
        
        # ç§»é™¤é»˜è®¤ç«¯å£
        if port and parsed.scheme in DEFAULT_PORTS and port == DEFAULT_PORTS[parsed.scheme]:
            # é‡å»ºnetlocï¼Œç§»é™¤ç«¯å£
            new_netloc = parsed.hostname
            if parsed.username:
                auth = parsed.username
                if parsed.password:
                    auth += f":{parsed.password}"
                new_netloc = f"{auth}@{new_netloc}"
            
            normalized_url = urlunparse((
                parsed.scheme,
                new_netloc,
                path,
                parsed.params,
                parsed.query,
                parsed.fragment
            ))
        
        return normalized_url
        
    except Exception as e:
        print(f"âš ï¸ å¤„ç†trackerå¤±è´¥ {tracker}: {e}")
        return None

def backup_and_save(trackers):
    """å¤‡ä»½æ—§æ–‡ä»¶å¹¶ä¿å­˜æ–°trackeråˆ—è¡¨"""
    print("ğŸ’¾ å¤‡ä»½å’Œä¿å­˜æ–‡ä»¶...")
    
    # ç¡®ä¿ç›®å½•å­˜åœ¨
    os.makedirs(os.path.dirname(LOCAL_TRACKER_FILE), exist_ok=True)
    
    # å¤‡ä»½ç°æœ‰æ–‡ä»¶
    if os.path.exists(LOCAL_TRACKER_FILE):
        timestamp = time.strftime("%Y%m%d_%H%M%S")
        backup_file = os.path.join(os.path.dirname(LOCAL_TRACKER_FILE), f"{timestamp}-trackers-back.txt")
        shutil.copy2(LOCAL_TRACKER_FILE, backup_file)
        print(f"âœ… å¤‡ä»½åˆ›å»º: {backup_file}")
    
    # ä¿å­˜æ–°æ–‡ä»¶
    try:
        with open(LOCAL_TRACKER_FILE, "w", encoding="utf-8") as f:
            f.write("\n".join(trackers) + "\n")
        print(f"âœ… æˆåŠŸä¿å­˜: {LOCAL_TRACKER_FILE}")
    except Exception as e:
        print(f"âŒ ä¿å­˜æ–‡ä»¶å¤±è´¥: {e}")
        return False
    
    # æ¸…ç†æ—§å¤‡ä»½
    try:
        backups = glob.glob(os.path.join(os.path.dirname(LOCAL_TRACKER_FILE), "*-trackers-back.txt"))
        backups.sort(key=os.path.getmtime, reverse=True)
        
        if len(backups) > BACKUP_KEEP_COUNT:
            for old_backup in backups[BACKUP_KEEP_COUNT:]:
                os.remove(old_backup)
                print(f"ğŸ—‘ï¸ åˆ é™¤æ—§å¤‡ä»½: {old_backup}")
    except Exception as e:
        print(f"âš ï¸ æ¸…ç†å¤‡ä»½å¤±è´¥: {e}")
    
    return True

def main():
    """ä¸»å¤„ç†å‡½æ•°"""
    print("ğŸš€ å¼€å§‹å¤„ç†trackeråˆ—è¡¨...")
    
    # 1. è·å–æ•°æ®
    all_text = fetch_all_sources()
    if not all_text.strip():
        print("âŒ æ²¡æœ‰è·å–åˆ°ä»»ä½•æ•°æ®")
        return
    
    # 2. åˆå§‹æ¸…ç†
    trackers = clean_and_split_text(all_text)
    
    # 3. ä¿®å¤åè®®æ ¼å¼
    trackers = fix_protocol_format(trackers)
    
    # 4. å¤„ç†åè®®å‰ç¼€ç²˜è¿
    trackers = handle_protocol_prefix_concatenation(trackers)
    
    # 5. åˆ†ç¦»ç²˜è¿tracker
    trackers = split_concatenated_trackers(trackers)
    
    # 6. è§„èŒƒåŒ–æ¯ä¸ªtracker
    print("âš™ï¸ è§„èŒƒåŒ–tracker URL...")
    normalized_trackers = []
    for tracker in trackers:
        normalized = normalize_tracker_url(tracker)
        if normalized:
            normalized_trackers.append(normalized)
    
    print(f"ğŸ“Š è§„èŒƒåŒ–å: {len(normalized_trackers)} ä¸ªtracker")
    
    # 7. å»é‡æ’åº
    unique_trackers = sorted(set(normalized_trackers))
    print(f"ğŸ¯ æœ€ç»ˆå»é‡å: {len(unique_trackers)} ä¸ªå”¯ä¸€tracker")
    
    # 8. ä¿å­˜ç»“æœ
    if backup_and_save(unique_trackers):
        print(f"âœ… å¤„ç†å®Œæˆ! å…± {len(unique_trackers)} ä¸ªtracker")
        
        # æ˜¾ç¤ºå‰10ä¸ªä½œä¸ºç¤ºä¾‹
        print("\nğŸ“‹ å‰10ä¸ªtrackerç¤ºä¾‹:")
        for i, tracker in enumerate(unique_trackers[:10]):
            print(f"  {i+1}. {tracker}")
    else:
        print("âŒ å¤„ç†å¤±è´¥")

if __name__ == "__main__":
    main()
